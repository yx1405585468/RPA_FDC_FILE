{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede4a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, max, col, countDistinct, when, rank, lit\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "\n",
    "\n",
    "# from backend_spark.doris_common.doris_client import DorisClient\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "301034e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#######################################解析SQL########################################\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bef77d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 这里使用doris数据库连接\n",
    "# user =\"root\"\n",
    "# host = \"10.52.199.81\"\n",
    "# password = \"Nexchip%40123\"\n",
    "# db = \"etl\"\n",
    "# port = 9030\n",
    "\n",
    "# engine = create_engine(\"mysql+pymysql://{user}:{password}@{host}:{port}/{db}\".format(user = user,\n",
    "#                                                                                     password = password,\n",
    "#                                                                                     host = host,\n",
    "#                                                                                     port = port,\n",
    "#                                                                                     db = db))\n",
    "\n",
    "# df1_pandas = pd.read_sql_query(\"SELECT * FROM etl.DWD_POC_CASE_FD_UVA_DATA_CASE1_PROCESSED1\", engine)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8edcefe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAFER_ID</th>\n",
       "      <th>TOOL_ID</th>\n",
       "      <th>RUN_ID</th>\n",
       "      <th>EQP_NAME</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODG1</th>\n",
       "      <th>TOOL_NAME</th>\n",
       "      <th>LOT_ID</th>\n",
       "      <th>RECIPE_NAME</th>\n",
       "      <th>OPER_NO</th>\n",
       "      <th>START_TIME</th>\n",
       "      <th>parametric_name</th>\n",
       "      <th>CASE_INFO</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>STATISTIC_RESULT</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NGE186-06</td>\n",
       "      <td>11341</td>\n",
       "      <td>149769</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AFKN2J01N.0U01</td>\n",
       "      <td>L11CD02A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGE186.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN0S0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-16 02:12:04</td>\n",
       "      <td>PROCESS_GAS_5_CHF3#WINDOW_1#SUM</td>\n",
       "      <td>2023-06-16</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>123907.6000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NGE186-06</td>\n",
       "      <td>11341</td>\n",
       "      <td>149769</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AFKN2J01N.0U01</td>\n",
       "      <td>L11CD02A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGE186.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN0S0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-16 02:12:04</td>\n",
       "      <td>PROCESS_GAS_4_CH2F2#WINDOW_1#SUM</td>\n",
       "      <td>2023-06-16</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NGE186-06</td>\n",
       "      <td>11341</td>\n",
       "      <td>149769</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AFKN2J01N.0U01</td>\n",
       "      <td>L11CD02A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGE186.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN0S0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-16 02:12:04</td>\n",
       "      <td>PROCESS_GAS_6_CF4#WINDOW_1#SUM</td>\n",
       "      <td>2023-06-16</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NGE186-06</td>\n",
       "      <td>11341</td>\n",
       "      <td>149769</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AFKN2J01N.0U01</td>\n",
       "      <td>L11CD02A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGE186.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN0S0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-16 02:12:04</td>\n",
       "      <td>ESC_CURRENT#AOTU_STEP_2#MEAN</td>\n",
       "      <td>2023-06-16</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NGE186-06</td>\n",
       "      <td>11341</td>\n",
       "      <td>149769</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AFKN2J01N.0U01</td>\n",
       "      <td>L11CD02A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGE186.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN0S0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-16 02:12:04</td>\n",
       "      <td>PROCESS_GAS_2_C4F8#AOTU_STEP_2#MEAN</td>\n",
       "      <td>2023-06-16</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550906</th>\n",
       "      <td>NGG239-19</td>\n",
       "      <td>11341</td>\n",
       "      <td>153513</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AMKNS301N.0B01</td>\n",
       "      <td>L11CB14A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGG239.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN9F0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-30 12:01:39</td>\n",
       "      <td>ESC_VOLTAGE#AOTU_STEP_2#MEAN</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>2503.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550907</th>\n",
       "      <td>NGG239-19</td>\n",
       "      <td>11341</td>\n",
       "      <td>153513</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AMKNS301N.0B01</td>\n",
       "      <td>L11CB14A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGG239.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN9F0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-30 12:01:39</td>\n",
       "      <td>PROCESS_GAS_11_N2#AOTU_STEP_2#MEAN</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550908</th>\n",
       "      <td>NGG239-19</td>\n",
       "      <td>11341</td>\n",
       "      <td>153513</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AMKNS301N.0B01</td>\n",
       "      <td>L11CB14A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGG239.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN9F0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-30 12:01:39</td>\n",
       "      <td>PROCESS_GAS_4_CH2F2#AOTU_STEP_2#MEAN</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550909</th>\n",
       "      <td>NGG239-19</td>\n",
       "      <td>11341</td>\n",
       "      <td>153513</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AMKNS301N.0B01</td>\n",
       "      <td>L11CB14A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGG239.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN9F0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-30 12:01:39</td>\n",
       "      <td>PROCESS_GAS_7_AR#AOTU_STEP_2#MEAN</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>199.9009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550910</th>\n",
       "      <td>NGG239-19</td>\n",
       "      <td>11341</td>\n",
       "      <td>153513</td>\n",
       "      <td>EKT72</td>\n",
       "      <td>AMKNS301N.0B01</td>\n",
       "      <td>L11CB14A</td>\n",
       "      <td>EKT72_PM1</td>\n",
       "      <td>NGG239.000</td>\n",
       "      <td>NEW-DRM/P1/110NM/PFKN9F0D1F1A</td>\n",
       "      <td>1F.EEK10</td>\n",
       "      <td>2023-06-30 12:01:39</td>\n",
       "      <td>LO_RF_VPP#STEP2_MINI#MEAN</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>880.3910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550911 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         WAFER_ID  TOOL_ID  RUN_ID EQP_NAME      PRODUCT_ID    PRODG1  \\\n",
       "0       NGE186-06    11341  149769    EKT72  AFKN2J01N.0U01  L11CD02A   \n",
       "1       NGE186-06    11341  149769    EKT72  AFKN2J01N.0U01  L11CD02A   \n",
       "2       NGE186-06    11341  149769    EKT72  AFKN2J01N.0U01  L11CD02A   \n",
       "3       NGE186-06    11341  149769    EKT72  AFKN2J01N.0U01  L11CD02A   \n",
       "4       NGE186-06    11341  149769    EKT72  AFKN2J01N.0U01  L11CD02A   \n",
       "...           ...      ...     ...      ...             ...       ...   \n",
       "550906  NGG239-19    11341  153513    EKT72  AMKNS301N.0B01  L11CB14A   \n",
       "550907  NGG239-19    11341  153513    EKT72  AMKNS301N.0B01  L11CB14A   \n",
       "550908  NGG239-19    11341  153513    EKT72  AMKNS301N.0B01  L11CB14A   \n",
       "550909  NGG239-19    11341  153513    EKT72  AMKNS301N.0B01  L11CB14A   \n",
       "550910  NGG239-19    11341  153513    EKT72  AMKNS301N.0B01  L11CB14A   \n",
       "\n",
       "        TOOL_NAME      LOT_ID                    RECIPE_NAME   OPER_NO  \\\n",
       "0       EKT72_PM1  NGE186.000  NEW-DRM/P1/110NM/PFKN0S0D1F1A  1F.EEK10   \n",
       "1       EKT72_PM1  NGE186.000  NEW-DRM/P1/110NM/PFKN0S0D1F1A  1F.EEK10   \n",
       "2       EKT72_PM1  NGE186.000  NEW-DRM/P1/110NM/PFKN0S0D1F1A  1F.EEK10   \n",
       "3       EKT72_PM1  NGE186.000  NEW-DRM/P1/110NM/PFKN0S0D1F1A  1F.EEK10   \n",
       "4       EKT72_PM1  NGE186.000  NEW-DRM/P1/110NM/PFKN0S0D1F1A  1F.EEK10   \n",
       "...           ...         ...                            ...       ...   \n",
       "550906  EKT72_PM1  NGG239.000  NEW-DRM/P1/110NM/PFKN9F0D1F1A  1F.EEK10   \n",
       "550907  EKT72_PM1  NGG239.000  NEW-DRM/P1/110NM/PFKN9F0D1F1A  1F.EEK10   \n",
       "550908  EKT72_PM1  NGG239.000  NEW-DRM/P1/110NM/PFKN9F0D1F1A  1F.EEK10   \n",
       "550909  EKT72_PM1  NGG239.000  NEW-DRM/P1/110NM/PFKN9F0D1F1A  1F.EEK10   \n",
       "550910  EKT72_PM1  NGG239.000  NEW-DRM/P1/110NM/PFKN9F0D1F1A  1F.EEK10   \n",
       "\n",
       "                 START_TIME                       parametric_name   CASE_INFO  \\\n",
       "0       2023-06-16 02:12:04       PROCESS_GAS_5_CHF3#WINDOW_1#SUM  2023-06-16   \n",
       "1       2023-06-16 02:12:04      PROCESS_GAS_4_CH2F2#WINDOW_1#SUM  2023-06-16   \n",
       "2       2023-06-16 02:12:04        PROCESS_GAS_6_CF4#WINDOW_1#SUM  2023-06-16   \n",
       "3       2023-06-16 02:12:04          ESC_CURRENT#AOTU_STEP_2#MEAN  2023-06-16   \n",
       "4       2023-06-16 02:12:04   PROCESS_GAS_2_C4F8#AOTU_STEP_2#MEAN  2023-06-16   \n",
       "...                     ...                                   ...         ...   \n",
       "550906  2023-06-30 12:01:39          ESC_VOLTAGE#AOTU_STEP_2#MEAN  2023-06-30   \n",
       "550907  2023-06-30 12:01:39    PROCESS_GAS_11_N2#AOTU_STEP_2#MEAN  2023-06-30   \n",
       "550908  2023-06-30 12:01:39  PROCESS_GAS_4_CH2F2#AOTU_STEP_2#MEAN  2023-06-30   \n",
       "550909  2023-06-30 12:01:39     PROCESS_GAS_7_AR#AOTU_STEP_2#MEAN  2023-06-30   \n",
       "550910  2023-06-30 12:01:39             LO_RF_VPP#STEP2_MINI#MEAN  2023-06-30   \n",
       "\n",
       "        STATUS  STATISTIC_RESULT  label  \n",
       "0       NORMAL       123907.6000      0  \n",
       "1       NORMAL            0.0000      0  \n",
       "2       NORMAL            0.0000      0  \n",
       "3       NORMAL           62.0000      0  \n",
       "4       NORMAL            0.0000      0  \n",
       "...        ...               ...    ...  \n",
       "550906  NORMAL         2503.0000      0  \n",
       "550907  NORMAL            0.0000      0  \n",
       "550908  NORMAL            0.0000      0  \n",
       "550909  NORMAL          199.9009      0  \n",
       "550910  NORMAL          880.3910      0  \n",
       "\n",
       "[550911 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_pandas = pd.read_csv(\"DWD_POC_CASE_FD_UVA_DATA_CASE1_PROCESSED1.csv\")\n",
    "df1_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532d39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  fields = [\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    }
   ],
   "source": [
    "df1 = ps.from_pandas(df1_pandas).to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295d7081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550911"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9318e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "######## 1. 客户只定义了bad_wafer = []是什么  ########\n",
    "############################################\n",
    "# 将传进来的BAD_WAFER, 用 | 连接起来，\n",
    "# F.col('WAFER_ID').like('NDJ065%') | F.col('WAFER_ID').like('NDJ067%') 作为条件传入增加label\n",
    "# 同时将isin模式也作为条件传入增加label\n",
    "\n",
    "def get_label_single(df, bad_wafer):\n",
    "    like_conditions = [f\"col('WAFER_ID').like('{bad}')\" for bad in bad_wafer]\n",
    "    all_like_conditions = \" | \".join(like_conditions)\n",
    "    isin_conditions = \"col('WAFER_ID').isin(bad_wafer)\"\n",
    "    df = df.withColumn('label', \n",
    "                when( eval(all_like_conditions) | eval(isin_conditions), int(1)).otherwise(int(0)))\n",
    "    return df\n",
    "\n",
    "\n",
    "############################################\n",
    "## 2. 客户定义了bad_wafer = [] 和 good_wafer = []######\n",
    "############################################\n",
    "# 将传进来的BAD_WAFER, 用 | 连接起来，\n",
    "# 将传进来的GOOD_WAFER, 也用 | 连接起来，\n",
    "# 同时将isin模式也作为条件传入增加label\n",
    "\n",
    "def get_label_double(df, bad_wafer, good_wafer):\n",
    "    good_like_conditions = [f\"col('WAFER_ID').like('{good}')\" for good in good_wafer]\n",
    "    all_good_like_conditions = \" | \".join(good_like_conditions)\n",
    "    good_isin_conditions = \"col('WAFER_ID').isin(good_wafer)\"\n",
    "\n",
    "    bad_like_conditions = [f\"col('WAFER_ID').like('{bad}')\" for bad in bad_wafer]\n",
    "    all_bad_like_conditions = \" | \".join(bad_like_conditions)\n",
    "    bad_isin_conditions = \"col('WAFER_ID').isin(bad_wafer)\"\n",
    "\n",
    "    df = df.withColumn('label',  when(eval(all_good_like_conditions) | eval(good_isin_conditions), int(0)).when(eval(all_bad_like_conditions) | eval(bad_isin_conditions), int(1)).otherwise(222333))\n",
    "    df = df.filter(df['label'] != int(222333))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c51449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small1.csv\n",
    "# good = [\"NBX221-13\",\"NBX220-06\",\"NBX272-19\",\"NBX219-08\"]\n",
    "# bad  = [\"NBX265-05\",\"NBX265-06\",\"NBX265-07\",\"NBX265-08\",\n",
    "#         \"NBX293-06\",\"NBX293-07\",\"NAZ998-21\",\"NBX220-20\"]\n",
    "\n",
    "# df1 = get_label_double(df1, bad, good)\n",
    "\n",
    "# small2.csv\n",
    "# good = [\"NBX221-13\",\"NBX220-06\",\"NBX272-19\",\"NBX219-08\"]\n",
    "# bad  = [\"NBX265-05\",\"NBX265-06\",\"NBX265-07\",\"NBX265-08\",\"NBX293-06\",\"NBX293-07\",\"NAZ998-21\",\"NBX220-20\"]\n",
    "\n",
    "# df1 = get_label_double(df1, bad, good)\n",
    "# df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc892ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2685\n",
      "3409\n"
     ]
    }
   ],
   "source": [
    "bad_wafer_num = df1.filter(\"label == 1\").select('WAFER_ID').distinct().count()\n",
    "good_wafer_num = df1.filter(\"label == 0\").select('WAFER_ID').distinct().count()\n",
    "print(bad_wafer_num)\n",
    "print(good_wafer_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beff31c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df1.filter(\"label == 1\").select('WAFER_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2306d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33326f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ec1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "##################################FDC数据预处理###############################\n",
    "############################################################################\n",
    "def _pre_process(df):\n",
    "    \"\"\"\n",
    "    param df: 从数据库中读取出来的某个CASE数据\n",
    "    return: 数据预处理，后面要根据实际情况统一添加\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 只选出会用到的列\n",
    "        df = df.select('WAFER_ID', 'TOOL_ID', 'RUN_ID', 'EQP_NAME', 'PRODUCT_ID', 'PRODG1', 'TOOL_NAME',\n",
    "                       'OPER_NO', 'parametric_name', 'STATISTIC_RESULT', 'label')\n",
    "        # 剔除NA值\n",
    "        df = df.filter(col('STATISTIC_RESULT').isNotNull())\n",
    "        # 按照所有的行进行去重\n",
    "        df1 = df.dropDuplicates()\n",
    "        # 选最新的RUN\n",
    "        df2 = df1.groupBy('WAFER_ID', 'OPER_NO', 'TOOL_ID').agg(max('RUN_ID').alias('RUN_ID'))\n",
    "        df_run = df1.join(df2.dropDuplicates(subset=['WAFER_ID', 'OPER_NO', 'TOOL_ID', 'RUN_ID']),\n",
    "                          on=['WAFER_ID', 'OPER_NO', 'TOOL_ID', 'RUN_ID'], how='inner')\n",
    "        return df_run\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def commonality_analysis(df_run, grpby_list):\n",
    "    \"\"\"\n",
    "    param df_run: 数据预处理后的数据\n",
    "    return: 共性分析后的结果， 返回bad wafer前十的组合\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grps = (df_run.groupBy(grpby_list)\n",
    "                .agg(countDistinct('WAFER_ID').alias('wafer_count'),\n",
    "                     countDistinct('WAFER_ID', when(df_run['label'] == 0, 1)).alias('good_num'),\n",
    "                     countDistinct('WAFER_ID', when(df_run['label'] == 1, 1)).alias('bad_num'))\n",
    "                .orderBy('bad_num', ascending=False))\n",
    "\n",
    "        # 单站点+单腔室的情况\n",
    "        if grps.count() == 1:\n",
    "            return grps\n",
    "        else:\n",
    "            grps = grps.filter(grps['bad_num'] > 0)\n",
    "            window_sep = Window().orderBy(col(\"bad_num\").desc())\n",
    "            ranked_df = grps.withColumn(\"rank\", rank().over(window_sep))\n",
    "            grpss = ranked_df.filter(col(\"rank\") <= 10).drop(\"rank\")\n",
    "            return grpss\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75015d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550896\n"
     ]
    }
   ],
   "source": [
    "df_run = _pre_process(df1)\n",
    "print(df_run.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20290123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+--------+-------+\n",
      "| OPER_NO|TOOL_NAME|wafer_count|good_num|bad_num|\n",
      "+--------+---------+-----------+--------+-------+\n",
      "|1F.EEK10|EKT72_PM1|       3892|    1207|   2685|\n",
      "+--------+---------+-----------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grpby_list = ['OPER_NO', 'TOOL_NAME']\n",
    "common_res = commonality_analysis(df_run, grpby_list)\n",
    "common_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c55b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ba88cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#################################获取样本数据#########################\n",
    "############################################################################\n",
    "def get_data_list(common_res, grpby_list, big_or_small='big'):\n",
    "    \"\"\"\n",
    "    param common_res: 共性分析后的结果, 按照大样本或者小样本条件筛选出组合\n",
    "    param grpby_list: 按照PRODG1+OPER_NO+TOOL_NAME分组或OPER_NO+TOOL_NAME分组\n",
    "    param big_or_small: big或者small\n",
    "    return: 对应组合的字典形式, 包在一个大列表中\n",
    "    \"\"\"\n",
    "    assert big_or_small in ['big', 'small'], \"只能选择big或者small, 请检查拼写\"\n",
    "    try:\n",
    "        if big_or_small == 'big':\n",
    "            good_bad_grps = common_res.filter(\"good_num >= 3 AND bad_num >= 3\")\n",
    "        else:\n",
    "            good_bad_grps = common_res.filter(\"bad_num >= 1 AND wafer_count >=2\")\n",
    "        good_bad_grps = good_bad_grps.orderBy(col(\"bad_num\").desc(), col(\"wafer_count\").desc(), col(\"good_num\").desc()).limit(5)\n",
    "        \n",
    "        if 'PRODG1' in grpby_list:\n",
    "            data_list = good_bad_grps['PRODG1', 'OPER_NO', 'TOOL_NAME'].collect()  \n",
    "        else:\n",
    "            data_list = good_bad_grps['OPER_NO', 'TOOL_NAME'].collect()\n",
    "            \n",
    "        data_dict_list = [row.asDict() for row in data_list]\n",
    "        return data_dict_list\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_train_data(df_run, data_dict_list):\n",
    "    \"\"\"\n",
    "    param df_run: 数据预处理后的数据\n",
    "    param data_dict: 筛选后的字典结果\n",
    "    return: 从原始数据中过滤出真正用来建模的组合数据\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(data_dict_list[0]) == 3:\n",
    "            prod, oper, tool = data_dict_list[0]['PRODG1'], data_dict_list[0]['OPER_NO'], data_dict_list[0]['TOOL_NAME']\n",
    "            df_s = df_run.filter(\"PRODG1 == '{}' AND OPER_NO == '{}' AND TOOL_NAME == '{}'\".format(prod, oper, tool))\n",
    "            for i in range(1, len(data_dict_list)):\n",
    "                prod, oper, tool = data_dict_list[i]['PRODG1'], data_dict_list[i]['OPER_NO'], data_dict_list[i]['TOOL_NAME']\n",
    "                df_m = df_run.filter(\"PRODG1 == '{}' AND OPER_NO == '{}' and TOOL_NAME == '{}'\".format(prod, oper, tool))\n",
    "                df_s = df_s.union(df_m)\n",
    "        else:\n",
    "            oper, tool = data_dict_list[0]['OPER_NO'], data_dict_list[0]['TOOL_NAME']\n",
    "            df_s = df_run.filter(\"OPER_NO == '{}' AND TOOL_NAME == '{}'\".format(oper, tool))\n",
    "            for i in range(1, len(data_dict_list)):\n",
    "                oper, tool = data_dict_list[i]['OPER_NO'], data_dict_list[i]['TOOL_NAME']\n",
    "                df_m = df_run.filter(\"OPER_NO == '{}' and TOOL_NAME == '{}'\".format(oper, tool))\n",
    "                df_s = df_s.union(df_m)\n",
    "        return df_s\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bed8418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'OPER_NO': '1F.EEK10', 'TOOL_NAME': 'EKT72_PM1'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_list_bs = get_data_list(common_res=common_res, grpby_list=grpby_list, big_or_small='big')\n",
    "data_dict_list_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "127c35c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268064\n"
     ]
    }
   ],
   "source": [
    "df_run_bs = get_train_data(df_run=df_run, data_dict_list=data_dict_list_bs)\n",
    "print(df_run_bs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280b1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a569a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#########################获取传入的整个数据中的所有bad_wafer个数####################\n",
    "############################################################################\n",
    "def get_all_bad_wafer_num(df):\n",
    "    \"\"\"\n",
    "    param df: 筛选后的数据\n",
    "    return: 数据中所有bad_wafer的数量\n",
    "    \"\"\"\n",
    "    return df.filter(\"label == 1\").select('WAFER_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25b9cc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2685"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_wafer_num_big_sample = get_all_bad_wafer_num(df_run_bs)\n",
    "bad_wafer_num_big_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515e601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebe3b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "###########################对有good和bad的数据，建模############################\n",
    "############################################################################\n",
    "def get_pivot_table(df, by):\n",
    "    if len(by) == 3:\n",
    "        df_pivot = df.dropna(axis=0).pivot_table(index=['WAFER_ID', 'label'], \n",
    "                                                     columns=['OPER_NO', 'TOOL_NAME', 'parametric_name', 'PRODG1'],\n",
    "                                                     values=['STATISTIC_RESULT'])\n",
    "    else:\n",
    "        df_pivot = df.dropna(axis=0).pivot_table(index=['WAFER_ID', 'label'], \n",
    "                                                     columns=['OPER_NO', 'TOOL_NAME', 'parametric_name'],\n",
    "                                                     values=['STATISTIC_RESULT'])\n",
    "    df_pivot.columns = df_pivot.columns.map('#'.join)\n",
    "    df_pivot = df_pivot.fillna(df_pivot.mean()).reset_index(drop=False)\n",
    "    return df_pivot\n",
    "\n",
    "\n",
    "\n",
    "def fit_rf_big_sample(df, by):\n",
    "    \"\"\"\n",
    "    param df: 大样本组合的数据\n",
    "    param by: 分组字段\n",
    "    return: RandomForest建模后的结果\n",
    "    \"\"\"\n",
    "    try:\n",
    "        schema_all = StructType([\n",
    "            StructField(\"PRODG1\", StringType(), True),\n",
    "            StructField(\"OPER_NO\", StringType(), True),\n",
    "            StructField(\"TOOL_NAME\", StringType(), True),\n",
    "            StructField(\"bad_wafer\", IntegerType(), True),\n",
    "            StructField(\"roc_auc_score\", FloatType(), True),\n",
    "            StructField(\"features\", StringType(), True),\n",
    "            StructField(\"importance\", FloatType(), True)])\n",
    "\n",
    "        @pandas_udf(returnType=schema_all, functionType=PandasUDFType.GROUPED_MAP)\n",
    "        def get_model_result(df_run):\n",
    "            df_pivot = get_pivot_table(df=df_run, by=by)\n",
    "\n",
    "            # 定义自变量和因变量\n",
    "            X_train = df_pivot[df_pivot.columns.difference(['WAFER_ID', 'label']).tolist()]\n",
    "            y_train = df_pivot[['label']]\n",
    "\n",
    "            z_ratio = y_train.value_counts(normalize=True)\n",
    "            good_ratio = z_ratio[0]\n",
    "            bad_ratio = z_ratio[1]\n",
    "            if abs(good_ratio - bad_ratio) > 0.7:\n",
    "                undersampler = ClusterCentroids(random_state=101)\n",
    "                X_train, y_train = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            # 网格搜索\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='constant', fill_value=-999)),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', RandomForestClassifier())])\n",
    "            param_grid = {'model__n_estimators': [*range(50, 100, 10)],\n",
    "                          'model__max_depth': [*range(10, 50, 10)]}\n",
    "            grid = GridSearchCV(estimator=pipe, scoring='roc_auc', param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "            grid.fit(X_train.values, y_train.values.ravel())\n",
    "            roc_auc_score_ = grid.best_score_\n",
    "\n",
    "            # 特征重要度、结果汇总\n",
    "            small_importance_res = pd.DataFrame({\n",
    "                'features': X_train.columns,\n",
    "                'importance': grid.best_estimator_.steps[2][1].feature_importances_}).sort_values(by='importance',\n",
    "                                                                                                  ascending=False)\n",
    "            if len(by) == 3:\n",
    "                small_sample_res = pd.DataFrame({\n",
    "                    'PRODG1': df_run['PRODG1'].unique(),\n",
    "                    'OPER_NO': df_run['OPER_NO'].unique(),\n",
    "                    'TOOL_NAME': df_run['TOOL_NAME'].unique(),\n",
    "                    'bad_wafer': sum(df_pivot['label']),\n",
    "                    'roc_auc_score': roc_auc_score_})\n",
    "            else:\n",
    "                PRODG1 = 'grplen2'\n",
    "                small_sample_res = pd.DataFrame({\n",
    "                    'PRODG1': PRODG1,\n",
    "                    'OPER_NO': df_run['OPER_NO'].unique(),\n",
    "                    'TOOL_NAME': df_run['TOOL_NAME'].unique(),\n",
    "                    'bad_wafer': sum(df_pivot['label']),\n",
    "                    'roc_auc_score': roc_auc_score_})\n",
    "            return pd.concat([small_importance_res, small_sample_res])\n",
    "        return df.groupby(by).apply(get_model_result)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99fa511f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+---------+-------------+--------------------+-----------+\n",
      "|PRODG1|OPER_NO|TOOL_NAME|bad_wafer|roc_auc_score|            features| importance|\n",
      "+------+-------+---------+---------+-------------+--------------------+-----------+\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...| 0.09229536|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...| 0.08904863|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.076730885|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...| 0.07044043|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...| 0.06887801|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.067021884|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.061975103|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.061536837|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.030265294|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.027252685|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.026130201|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.025756838|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.025425736|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.021406628|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.018448958|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.018251002|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.016720226|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...| 0.01464348|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.012427809|\n",
      "|  null|   null|     null|     null|         null|STATISTIC_RESULT#...|0.011083875|\n",
      "+------+-------+---------+---------+-------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = fit_rf_big_sample(df=df_run_bs, by=grpby_list)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bf9431b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['STATISTIC_RESULT#1F.EEK10#EKT72_PM1#LO_RF_VPP#STEP2_MEANDIFF#MEAN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.toPandas()[['features']].iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d25c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98190aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#########################对有good和bad的建模后的结果进行整合###############################\n",
    "#####################################################################################\n",
    "def split_score_big_sample(df, by):\n",
    "    \"\"\"\n",
    "    param df: RandomForest建模后的结果\n",
    "    param by: 分组字段\n",
    "    return: roc_auc分数结果\n",
    "    \"\"\"\n",
    "    try:\n",
    "        schema_all = StructType([StructField(\"PRODG1\", StringType(), True),\n",
    "                                 StructField(\"OPER_NO\", StringType(), True),\n",
    "                                 StructField(\"TOOL_NAME\", StringType(), True),\n",
    "                                 StructField(\"bad_wafer\", IntegerType(), True),\n",
    "                                 StructField(\"roc_auc_score\", FloatType(), True)])\n",
    "\n",
    "        @pandas_udf(returnType=schema_all, functionType=PandasUDFType.GROUPED_MAP)\n",
    "        def get_result(model_results):\n",
    "            sample_res = model_results[['PRODG1', 'OPER_NO', 'TOOL_NAME', 'bad_wafer', 'roc_auc_score']].dropna(axis=0)\n",
    "            sample_res = sample_res[sample_res['roc_auc_score'] > 0.6]\n",
    "            return sample_res\n",
    "        return df.groupby(by).apply(get_result)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42947aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/group_ops.py:98: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+---------+-------------+\n",
      "| PRODG1| OPER_NO|TOOL_NAME|bad_wafer|roc_auc_score|\n",
      "+-------+--------+---------+---------+-------------+\n",
      "|grplen2|1F.EEK10|EKT72_PM1|     2685|   0.92144805|\n",
      "+-------+--------+---------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_res = split_score_big_sample(df=res, by=['PRODG1', 'OPER_NO', 'TOOL_NAME'])\n",
    "s_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfc2a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features(df, index) -> str:\n",
    "    \"\"\"\n",
    "    param df: RandomForest建模后的feature_importance_table\n",
    "    param index: 顺序值\n",
    "    return: 字段属性值\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return df['features'].apply(lambda x: x.split('#')[index])\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_split_feature_importance_table(df, by):\n",
    "    \"\"\"\n",
    "    param df: RandomForest建模后的feature_importance_table\n",
    "    param by: OPER_NO+TOOL_NAME+PRODG1或者OPER_NO+TOOL_NAME\n",
    "    return: 分裂features后的表\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df['STATISTIC_RESULT'] = split_features(df, 0)\n",
    "        df['OPER_NO'] = split_features(df, 1)\n",
    "        df['TOOL_NAME'] = split_features(df, 2)\n",
    "        df['parametric_name'] = split_features(df, 3)\n",
    "        df['step'] = split_features(df, 4)\n",
    "        df['stats'] = split_features(df, 5)\n",
    "\n",
    "        if 'PRODG1' in by:\n",
    "            df['PRODG1'] = split_features(df, 6)\n",
    "        else:\n",
    "            df = df.assign(PRODG1 = 'grplen2')\n",
    "\n",
    "        df = df.drop(['features', 'STATISTIC_RESULT'], axis=1).reset_index(drop=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def add_feature_stats(df):\n",
    "    \"\"\"\n",
    "    param df: 经过处理后的feature_importance_table\n",
    "    return: 新增一列，含有参数的所有统计特征:feature_stats\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feature_stats = df.groupby(['PRODG1', 'OPER_NO', 'TOOL_NAME', 'parametric_name', 'step'])['stats'].unique().reset_index()\n",
    "        feature_stats['stats'] = [feature_stats['stats'].iloc[i].tolist() for i in range(len(feature_stats))]\n",
    "        feature_stats['stats'] = feature_stats['stats'].apply(lambda x: \"#\".join(x))\n",
    "        feature_stats = feature_stats.assign(parametric_name=lambda x: x['parametric_name']+str('#')+x['step']).drop('step', axis=1)\n",
    "        return feature_stats\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee24400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_calculate_features_big_sample(df, by):\n",
    "    \"\"\"\n",
    "    param df: RandomForest建模后的结果\n",
    "    param by: 分组字段\n",
    "    return: features和importance结果\n",
    "    \"\"\"\n",
    "    try:\n",
    "        schema_all = StructType([\n",
    "            StructField(\"PRODG1\", StringType(), True),\n",
    "            StructField(\"OPER_NO\", StringType(), True),\n",
    "            StructField(\"TOOL_NAME\", StringType(), True),\n",
    "            StructField(\"parametric_name\", StringType(), True),\n",
    "            StructField(\"importance\", FloatType(), True),\n",
    "            StructField(\"stats\", StringType(), True)])\n",
    "\n",
    "        @pandas_udf(returnType=schema_all, functionType=PandasUDFType.GROUPED_MAP)\n",
    "        def get_result(model_results):\n",
    "            # 先从随机森林的模型结果中取出包含features和importance的dataframe\n",
    "            feature_importance_table = model_results[['features', 'importance']].dropna(axis=0)\n",
    "            # 分裂features\n",
    "            feature_importance_res_split = get_split_feature_importance_table(feature_importance_table, by)\n",
    "\n",
    "            # 去除importance为0的组合\n",
    "            feature_importance_res_split_drop = feature_importance_res_split.query(\"importance > 0\").reset_index(drop=True)\n",
    "\n",
    "            # 取每一种组合结果的前60%\n",
    "            feature_importance_res_split_nlargest = (feature_importance_res_split_drop.groupby(by=['PRODG1', 'OPER_NO', 'TOOL_NAME'])\n",
    "                                                .apply(lambda x: x.nlargest(int(x.shape[0]*0.6), 'importance') if x.shape[0]>1 else x.nlargest(int(x.shape[0]*1), 'importance'))\n",
    "                                                .reset_index(drop=True))\n",
    "            # 新增一列，含有参数的所有统计特征:feature_stats\n",
    "            feature_stats = add_feature_stats(feature_importance_res_split_drop)\n",
    "\n",
    "            # 对同一种组合里的同一个参数进行求和:feature_importance_groupby\n",
    "            feature_importance_groupby = (feature_importance_res_split_nlargest.groupby(['PRODG1', 'OPER_NO', 'TOOL_NAME',\n",
    "                                                                'parametric_name', 'step'])['importance'].sum().reset_index())\n",
    "            feature_importance_groupby = feature_importance_groupby.assign(parametric_name=lambda x: x['parametric_name'] + str('#') + x['step']).drop('step', axis=1)\n",
    "\n",
    "            # feature_stats和feature_importance_groupby连接\n",
    "            grpby_stats = pd.merge(feature_stats, feature_importance_groupby, on=['PRODG1', 'OPER_NO', 'TOOL_NAME', 'parametric_name']).dropna().reset_index(drop=True)\n",
    "            return grpby_stats\n",
    "        return df.groupby(by).apply(get_result)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a54fb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+------------+----------+\n",
      "| PRODG1| OPER_NO|TOOL_NAME|     parametric_name|  importance|     stats|\n",
      "+-------+--------+---------+--------------------+------------+----------+\n",
      "|grplen2|1F.EEK10|EKT72_PM1|APC_POSITION#AOTU...| 0.020515786|MEAN#RANGE|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|AUTO_CHECK_LEAK_R...| 0.016150674|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|BOTTOMFLOWRATE#AO...|0.0058746045|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|CENTER_GAS_PRESSU...|  0.08329593|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|CENTER_GAS_PRESSU...|  3.65964E-4|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|CHAMBER_PRESSURE#...| 0.013456499|RANGE#MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|CHAMBER_PRESSURE#...| 0.001026323|RANGE#MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|CHAMBER_PRESSURE#...|3.7905315E-4|RANGE#MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|EDGE_GAS_PRESSURE...|  0.04766397|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|EDGE_HE_FLOW#AOTU...| 0.034963492|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|EDGE_HE_FLOW#AOTU...|4.5389432E-4|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|EDGE_HE_FLOW#AOTU...|0.0010796079|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...| 0.099804655|  MEAN#MAX|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...| 0.010590062|  MEAN#MAX|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...| 0.013018273|  MEAN#MAX|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...| 0.014131229|  MEAN#MAX|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_VOLTAGE#AOTU_...|0.0016054026|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_VOLTAGE#AOTU_...|0.0015740646|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|FLOWSPLITCENTER#A...|  0.07383077|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|FLOWSPLITCENTER#A...| 3.831913E-4|      MEAN|\n",
      "+-------+--------+---------+--------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_res = split_calculate_features_big_sample(df=res, by=grpby_list)\n",
    "f_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4ac17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dddfc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finall_results_big_sample(s_res, f_res, bad_wafer_num):\n",
    "    \"\"\"\n",
    "    param s_res: roc_auc分数结果\n",
    "    param f_res: features和importance结果\n",
    "    param bad_wafer_num: 数据中所有bad_wafer的数量\n",
    "    return: 最后的建模结果\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # feature_importance_groupby和sample_res连接\n",
    "        roc_auc_score_all = s_res.agg({\"roc_auc_score\": \"sum\"}).collect()[0][0]\n",
    "        s_res = s_res.withColumn(\"roc_auc_score_ratio\", col(\"roc_auc_score\")/roc_auc_score_all)\n",
    "        s_res = s_res.withColumn(\"bad_ratio\", col(\"bad_wafer\") / bad_wafer_num)\n",
    "\n",
    "        df_merge = s_res.join(f_res, on=['PRODG1', 'OPER_NO', 'TOOL_NAME'], how='left')\n",
    "        df_merge = df_merge.withColumn('weight_original', col('roc_auc_score_ratio') * col('bad_ratio') * col('importance'))\n",
    "\n",
    "        # 最后再次进行一次归一化\n",
    "        weight_all = df_merge.agg({\"weight_original\": \"sum\"}).collect()[0][0]\n",
    "        df_merge = df_merge.withColumn(\"weight\", col(\"weight_original\") / weight_all)\n",
    "\n",
    "        df_merge = df_merge.select(['PRODG1', 'OPER_NO', 'TOOL_NAME',\n",
    "                                    'parametric_name', 'weight', 'stats']).orderBy('weight', ascending=False)\n",
    "        return df_merge\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b556a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+--------------------+----------+\n",
      "| PRODG1| OPER_NO|TOOL_NAME|     parametric_name|              weight|     stats|\n",
      "+-------+--------+---------+--------------------+--------------------+----------+\n",
      "|grplen2|1F.EEK10|EKT72_PM1|LO_RF_VPP#AOTU_ST...|  0.1380923275625163|MEAN#SLOPE|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...| 0.11275109016774493|  MEAN#MAX|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|FLOWSPLITEDGE#AOT...| 0.08739145393710289|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|LO_RF_VPP#STEP2_M...|  0.0687084866149236|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|LO_RF_VPP#STEP2_MINI| 0.06761170739685284|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|CENTER_GAS_PRESSU...| 0.06206230109582653|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|FLOWSPLITCENTER#A...| 0.05986446560566939|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|LO_RF_REF_POWER#A...|0.044597637602787975|  MEAN#MAX|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|EDGE_GAS_PRESSURE...| 0.03774605219229366|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|EDGE_HE_FLOW#AOTU...| 0.03539282457650606|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|PROCESS_GAS_8_O2#...| 0.03123910354041368|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|LO_RF_POWER#AOTU_...|0.019859052126023787|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|LOWER_TEMPERATURE...|0.019755928226725374|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|APC_POSITION#AOTU...| 0.01786885260111766|MEAN#RANGE|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|AUTO_CHECK_LEAK_R...|0.015499327158449505|      MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|CHAMBER_PRESSURE#...| 0.01490100106788094|RANGE#MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...|0.014756524809494718|  MAX#MEAN|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|LO_C1_VAR_CAPACIT...|0.013351991858041203|     SLOPE|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...|0.012647856516058719|  MEAN#MAX|\n",
      "|grplen2|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...| 0.01260260978673564|  MEAN#MAX|\n",
      "+-------+--------+---------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_res_bs = get_finall_results_big_sample(s_res=s_res, f_res=f_res, bad_wafer_num=bad_wafer_num_big_sample)\n",
    "model_res_bs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ced8174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+--------------------+--------------------+----------+\n",
      "|  PRODG1| OPER_NO|TOOL_NAME|     parametric_name|              weight|     stats|\n",
      "+--------+--------+---------+--------------------+--------------------+----------+\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|LO_RF_VPP#STEP2_M...| 0.13372307777728373|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|LO_RF_VPP#AOTU_ST...| 0.12585516985139056|MEAN#SLOPE|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|LO_RF_VPP#STEP2_MINI| 0.09897470007721072|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|PROCESS_GAS_8_O2#...| 0.06904437281416093|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|LOWER_TEMPERATURE...| 0.05277240244502971|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|LO_RF_REF_POWER#A...| 0.05168048646062583|  MEAN#MAX|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|LO_C1_VAR_CAPACIT...| 0.04450558511062986|     SLOPE|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|CHAMBER_PRESSURE#...|0.031448298017748656|RANGE#MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|CENTER_GAS_PRESSU...|0.030208098282600737|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|EDGE_HE_FLOW#AOTU...|0.028559950122778302|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|FLOWSPLITCENTER#A...|0.028147565360293912|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|EDGE_GAS_PRESSURE...|0.026518296852682654|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|LO_C2_VAR_CAPACIT...|0.023801702651963404|     RANGE|\n",
      "|L15RB03A|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...| 0.02340920628496534|  MEAN#MAX|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|FLOWSPLITEDGE#AOT...| 0.02218728092306166|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|UPPER_TEMPERATURE...| 0.02155930642315667|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|WALL_TEMPERATURE#...|0.019179072276111528|      MEAN|\n",
      "|L11CD02A|1F.EEK10|EKT72_PM1|LO_RF_POWER#AOTU_...| 0.01903639101659447|      MEAN|\n",
      "|L15RB03A|1F.EEK10|EKT72_PM1|ESC_CURRENT#AOTU_...|0.016473268660816914|  MEAN#MAX|\n",
      "|L15RB03A|1F.EEK10|EKT72_PM1|LO_RF_VPP#AOTU_ST...|0.013302984641082745|SLOPE#MEAN|\n",
      "+--------+--------+---------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_res_bs = get_finall_results_big_sample(s_res=s_res, f_res=f_res, bad_wafer_num=bad_wafer_num_big_sample)\n",
    "model_res_bs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d259ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22f81b96",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "86249030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_res_split1 = pd.DataFrame(\n",
    "#     {'PRODG1': ['grplen2', 'grplen2', 'grplen2', 'grplen2', 'grplen2'],\n",
    "#     'TOOL_NAME': ['PBT01_CGHA_4-14', 'PBT01_CGHA_4-14', 'PBT01_CGHA_4-14', 'PBT01_CGHA_4-13', 'PBT01_CGHA_4-13'],\n",
    "#     'OPER_NO': ['1V.PPB10', '1V.PPB10', '1V.PPB10', '1V.PPB10', '1V.PPB10'],\n",
    "#     'parametric_name': ['PLATE_TEMP', 'PLATE_TEMP', 'PLATE_TEMP', 'PLATE_TEMP', 'PLATE_TEMP'],\n",
    "#     'importance': [0.7,0.2,0.1,0.9,0.1]},\n",
    "# )\n",
    "# feature_importance_res_split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "459b05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取每一种组合结果的前60%\n",
    "# feature_importance_res_split_nlargest = (feature_importance_res_split1.groupby(by=['PRODG1', 'OPER_NO', 'TOOL_NAME'])\n",
    "#     .apply(lambda x: x.nlargest(int(x.shape[0]*1), 'importance') if x.shape[0]>1 else x.nlargest(int(x.shape[0]*1), 'importance'))\n",
    "#     .reset_index(drop=True))\n",
    "# feature_importance_res_split_nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06a23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b77d876a",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b87fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb7f1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#############################将建模后的结果增加特定的列####################################\n",
    "#####################################################################################\n",
    "def add_certain_column(df, by, request_id):\n",
    "    \"\"\"\n",
    "    param df: 最后的建模结果\n",
    "    param by: 分组字段, 手动增加一列add\n",
    "    param request_id: 传入的request_id\n",
    "    return: 最后的建模结果增加特定的列\n",
    "    \"\"\"\n",
    "    try:\n",
    "        schema_all = StructType([\n",
    "            StructField(\"PRODG1\", StringType(), True),\n",
    "            StructField(\"OPER_NO\", StringType(), True),\n",
    "            StructField(\"TOOL_NAME\", StringType(), True),\n",
    "            StructField(\"stats\", StringType(), True),\n",
    "            StructField(\"parametric_name\", StringType(), True),\n",
    "            StructField(\"weight\", FloatType(), True),\n",
    "            StructField(\"request_id\", StringType(), True),\n",
    "            StructField(\"weight_percent\", FloatType(), True),\n",
    "            StructField(\"index_no\", IntegerType(), True)])\n",
    "\n",
    "        @pandas_udf(returnType=schema_all, functionType=PandasUDFType.GROUPED_MAP)\n",
    "        def get_result(final_res):\n",
    "            final_res['weight'] = final_res['weight'].astype(float)\n",
    "            final_res = final_res.query(\"weight > 0\")\n",
    "            final_res['request_id'] = request_id\n",
    "            final_res['weight_percent'] = final_res['weight'] * 100\n",
    "            final_res = final_res.sort_values('weight', ascending=False)\n",
    "            final_res['index_no'] = [i + 1 for i in range(len(final_res))]\n",
    "            final_res = final_res.drop('add', axis=1)\n",
    "            # final_res['parametric_name'] = final_res['parametric_name'].str.replace(\"_\", \"+\")\n",
    "            final_res['PRODG1'] = final_res['PRODG1'].apply(lambda x: None if x == 'grplen2' else x)\n",
    "            return final_res\n",
    "        return df.groupby(by).apply(get_result)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "952c6d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/group_ops.py:98: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----+--------------------+------+----------+--------------+--------+\n",
      "|PRODG1| OPER_NO|      TOOL_NAME|stats|     parametric_name|weight|request_id|weight_percent|index_no|\n",
      "+------+--------+---------------+-----+--------------------+------+----------+--------------+--------+\n",
      "|  null|1V.PPB10|PBT01_CGHA_4-14| MEAN|PLATE_TEMP#HDB205...|   1.0|      fdsf|         100.0|       1|\n",
      "+------+--------+---------------+-----+--------------------+------+----------+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_id = 'fdsf'\n",
    "final_res_bs = model_res_bs.withColumn('add', lit(0))\n",
    "final_res_add_columns = add_certain_column(df=final_res_bs, by='add', request_id=request_id)\n",
    "final_res_add_columns.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efb1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57095241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca8bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c22c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a3a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2de40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d20037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83260e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811c39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bff3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a037b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f854840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "################################将最后的结果写回数据库####################################\n",
    "#####################################################################################\n",
    "def doris_stream_load_from_df(df, engine, table, is_json=True, chunksize=100000, partitions=None):\n",
    "    engine_url = engine.url\n",
    "    url = 'http://%s:18030/api/%s/%s/_stream_load' % (engine_url.host, engine_url.database, table)\n",
    "\n",
    "    format_str = 'csv' if not is_json else 'json'\n",
    "    headers = {\n",
    "        'Content-Type': 'text/plain; charset=UTF-8',\n",
    "        'format': format_str,\n",
    "        'Expect': '100-continue'\n",
    "    }\n",
    "    if is_json:\n",
    "        headers['strip_outer_array'] = 'true'\n",
    "        headers['read_json_by_line'] = 'true'\n",
    "    else:\n",
    "        headers['column_separator'] = '@'\n",
    "    \n",
    "    if partitions:\n",
    "        headers['partitions'] = partitions\n",
    "    \n",
    "    auth = requests.auth.HTTPBasicAuth(engine_url.username, engine_url.password)\n",
    "    session = requests.sessions.Session()\n",
    "    session.should_strip_auth = lambda old_url, new_url: False\n",
    "    \n",
    "    l = len(df)\n",
    "    if l > 0:\n",
    "        if chunksize and chunksize < l:\n",
    "            batches = l // chunksize\n",
    "            if l % chunksize > 0:\n",
    "                batches += 1\n",
    "            for i in range(batches):\n",
    "                si = i * chunksize\n",
    "                ei = min(si + chunksize, l)\n",
    "                sub = df[si:ei]\n",
    "                do_doris_stream_load_from_df(sub, session, url, headers, auth, is_json)\n",
    "        else:\n",
    "            do_doris_stream_load_from_df(df, session, url, headers, auth, is_json)\n",
    "\n",
    "\n",
    "def do_doris_stream_load_from_df(df, session, url, headers, auth, is_json=False):\n",
    "    data = df.to_csv(header=False, index=False, sep='@') if not is_json else df.to_json(orient='records', date_format='iso')\n",
    "    #print(data)\n",
    "    \n",
    "    resp = session.request(\n",
    "        'PUT',\n",
    "        url = url,\n",
    "        data=data.encode('utf-8'),\n",
    "        headers=headers,\n",
    "        auth=auth\n",
    "    )\n",
    "    print(resp.reason, resp.text)\n",
    "    check_stream_load_response(resp.text)\n",
    "\n",
    "\n",
    "def check_stream_load_response(resp_text):\n",
    "    resp = json.loads(resp_text)\n",
    "    if resp['Status'] not in [\"Success\", \"Publish Timeout\"]:\n",
    "        raise Exception(resp['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c88ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe2cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f76af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1076e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbacf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b936d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fcc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e28f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea005b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd225c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dcd1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bafdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68da02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67c01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41761a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205380e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf5a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3f138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b2627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb553b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9008dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042bf618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a2b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49bdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a889319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc383b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c1eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa9a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf8b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
